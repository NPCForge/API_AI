package sharedServices

import (
	"errors"
	"fmt"
	"my-api/internal/services"
	"my-api/internal/services/helpers"
	"my-api/internal/services/shared/decisions"
	"my-api/internal/utils"
	"my-api/pkg"
	"strings"
)

// interpretLLMDecision interprets a decision string generated by the LLM and dispatches it to the appropriate handler.
func interpretLLMDecision(Decision string, Checksum string) (string, error) {
	if strings.Contains(Decision, "TalkTo:") {
		return decisions.HandleTalkToLogic(Decision, Checksum)
	}

	return "", fmt.Errorf("no such decision: %s", Decision)
}

// askLLMForDecision builds a user prompt, sends it to the LLM, and returns the generated decision.
func askLLMForDecision(Message string, Checksum string) (string, error) {
	discussion, err := helpers.GetAllDiscussions(Checksum)
	if err != nil {
		return "", err
	}

	Message += "\nDiscussion: {" + discussion + "}"

	// Read the "Decision.txt" file to get the system prompt
	systemPrompt, err := services.ReadPromptFromFile("prompts/Decision.txt")
	if err != nil {
		return "", fmt.Errorf("error retrieving the system prompt: %w", err)
	}

	decision, err := services.GptSimpleRequest(Message, systemPrompt)
	if err != nil {
		pkg.DisplayContext("GptSimpleRequest failed:", pkg.Error, err)
		return "", err
	}

	return decision, nil
}

func shouldMakeDecision(Message string, Checksum string) (bool, error) {
	discussion, err := helpers.GetAllDiscussions(Checksum)
	if err != nil {
		return false, err
	}

	Message += "\nDiscussion: {" + discussion + "}"

	// Read the "ShouldTalk.txt" file to get the system prompt
	systemPrompt, err := services.ReadPromptFromFile("prompts/ShouldTalk.txt")

	if err != nil {
		return false, fmt.Errorf("error retrieving the system prompt: %w", err)
	}

	response, err := services.GptSimpleRequest(Message, systemPrompt)
	if err != nil {
		pkg.DisplayContext("GptSimpleRequest failed:", pkg.Error, err)
		return false, err
	}

	if strings.Contains(response, "Speak: yes") {
		pkg.DisplayContext("IA decided to speak", pkg.Debug)
		return true, nil
	} else if strings.Contains(response, "Speak: no") {
		pkg.DisplayContext("IA decided not to speak : "+response, pkg.Debug)
		return false, nil
	} else {
		pkg.DisplayContext("Cannot get response format in shouldMakeDecision", pkg.Error)
		return false, fmt.Errorf("cannot get response format in shouldMakeDecision")
	}
}

// MakeDecisionService checks access rights, queries the LLM for a decision, and interprets the response.
func MakeDecisionService(Message string, Checksum string, Token string) (string, error) {
	id, err := utils.GetUserIDFromJWT(Token)
	if err != nil {
		return "", err
	}

	val, err := helpers.IsMyEntity(Checksum, id)
	if err != nil {
		return "", err
	}

	if !val {
		return "", errors.New("access denied to this entity")
	}

	shouldDecision, err := shouldMakeDecision(Message, Checksum)

	if err != nil {
		return "", err
	}

	if !shouldDecision {
		return "No Action", nil
	}

	decision, err := askLLMForDecision(Message, Checksum)
	if err != nil {
		pkg.DisplayContext("Error after decision making:", pkg.Error, err)
		return "", err
	}

	task, err := interpretLLMDecision(decision, Checksum)
	if err != nil {
		pkg.DisplayContext("Error after LLM response interpretation:", pkg.Error, err)
		return "", err
	}

	return task, nil
}
